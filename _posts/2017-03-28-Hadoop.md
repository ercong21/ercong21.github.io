---
layout: post
title: CentOS7 下分布式安装 Hadoop
categories: Tool
description: CentOS7下分布式安装Hadoop
keywords: Linux, Hadoop, Hadoop安装
---

一直想学习一下云计算方面的知识，但由于各种原因都没能开始，这次刚好有作业上的要求，所以也是学习了一下CentOS下Hadoop的分布式安装，下面分享一下安装过程。

### 前期准备

#### 环境

实验用到是两台CentOS7，64位的计算机，其中一台是真机（充当master角色），一台是虚拟机（充当slave角色）。

#### 配置hosts文件

为了让后续的工作不受ip影响，所以在两台机器的host文件中都配置以下信息：

```shell
116.57.53.134 master
192.168.30.128 slave
```

#### 关闭防火墙

```shell
# 查看防火墙状态
systemctl status firewalld.service
# 关闭防火墙
systemctl stop firewalld.service
# 永久关闭防火墙
systemctl disable firewalld.service
```

#### 创建hadoop用户并用ssh配置无密码登录

在master上面的操作：

```shell
useradd hadoop
passwd hadoop
su hadoop
ssh-keygen -t rsa -P ''
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
su
vim /etc/ssh/sshd_config
# 修改ssh配置文件如下
# RSAAuthentication yes
# PubkeyAuthentication yes
# AuthorizedKeysFile .ssh/authorized_keys
# su hadoop --切换到hadoop用户
scp ~/.ssh/id_rsa.pub hadoop@slave:~/
```

在slave1上面的操作：

```shell
useradd hadoop
passwd hadoop
su hadoop
mkdir ~/.ssh
chmod 700 ~/.ssh
cat ~/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys
su
# 编辑ssh配置文件，步骤与上面的一样
vim /etc/ssh/sshd_config
```

### 具体步骤

#### 安装JDK

下载JDK并配置环境变量，这里略

#### 下载Hadoop并进行配置

可以先把Hadoop先下载到master，等配置好之后再传到slave上

##### 步骤一：解压下载文件并把它的用户设为Hadoop

```shell
cd /usr
tar zxvf hadoop-2.6.0.tar.gz
mv hadoop-2.6.0 hadoop
chown -R hadoop:hadoop hadoop
```

##### 步骤二：切换到Hadoop用户并进行一些基础配置

```shell
su hadoop
cd /usr/hadoop
mkdir -p dfs/name
mkdir -p dfs/data
mkdir -p tmp
cd etc/hadoop
```

另外，还要在/etc/profile中进行环境变量的配置，具体如下：

```
export HADOOP_HOME=/usr/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
```

配置完还要使用`source /etc/profile`使命令生效。

##### 步骤三：配置hadoop-env.sh和yarn-env.sh

这两个文件主要是要修改JAVA_HOME变量，可以在文件中查找带有export JAVA_HOME这一行的语句进行配置。

##### 步骤四：配置core-site.xml

```
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/usr/hadoop/tmp</value>
    </property>
    <property>
        <name>io.file.buffer.size</name>
        <value>131702</value>
    </property>
</configuration>
```

##### 步骤五：配置hdfs-site.xml

```
<configuration>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/usr/hadoop/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/usr/hadoop/dfs/data</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>master:9001</value>
    </property>
    <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
    </property>
</configuration>
```

##### 步骤六：配置slaves

这个文件主要是配置slave主机，由于我们前面已经配置过hosts文件了，所以这里不用输入ip地址，直接把文件修改为以下样子即可：

```
slave
```

### 最终效果

#### 启动hadoop

```shell
cd /usr/hadoop
./sbin/start-dfs.sh
./sbin/start-yarn.sh
```

其中第二行代码的输出日志为：

```
Starting namenodes on [master]
master: starting namenode, logging to /usr/hadoop/logs/hadoop-hadoop-namenode-master.out
slave: starting datanode, logging to /usr/hadoop/logs/hadoop-hadoop-datanode-slave.out
Starting secondary namenodes [master]
master: starting secondarynamenode, logging to /usr/hadoop/logs/hadoop-hadoop-secondarynamenode-master.out
```

第三行代码的输出日志为：

```
starting yarn daemons
starting resourcemanager, logging to /usr/hadoop/logs/yarn-hadoop-resourcemanager-master.out
slave: starting nodemanager, logging to /usr/hadoop/logs/yarn-hadoop-nodemanager-slave.out
```

### 参考资料

- [CentOS7安装Hadoop2.7完整流程](https://my.oschina.net/lizhiling/blog/472814)
- [CentOS 7.0 hadoop 安装与配置](http://www.jianshu.com/p/859e10af9796)
- [CentOS7-64bit 编译 Hadoop-2.5.0，并分布式安装](https://my.oschina.net/u/1428349/blog/313646)